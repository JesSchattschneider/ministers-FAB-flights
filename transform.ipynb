{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from utils import Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all_data.csv exists, if it doesn't, run function to create it:\n",
    "if os.path.exists(\"all_data.csv\"):\n",
    "    data = pd.read_csv(\"all_data.csv\", dtype = str)\n",
    "else:\n",
    "    Wrangling.save_tables_from_pdfs()\n",
    "    data = pd.read_csv(\"all_data.csv\", dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_problem = pd.read_csv(\"all_data.csv\", dtype = str) ## we have issue with tables that share multiple ministerios and same dates... check 20220218_135419.pdf. These files will be removed\n",
    "data_problem[\"file_name\"] = data_problem[\"file_name\"].astype(str)\n",
    "data_problem = data_problem[~data_problem[\"file_name\"].str.contains(\"pdf\")]\n",
    "\n",
    "# we could potentially keep these:\n",
    "# data_problem[\"previsao_de_passageiros\"] = data_problem[\"previsao_de_passageiros\"].astype(str)\n",
    "# data_problem = data_problem[~data_problem[\"previsao_de_passageiros\"].str.contains(\"pdf\")]\n",
    "\n",
    "pd.DataFrame(data_problem).to_csv(\"fix.csv\") # save for checking\n",
    "\n",
    "# keep only \"good quality\" data:\n",
    "data[\"file_name\"] = data[\"file_name\"].astype(str)\n",
    "data = data[data[\"file_name\"].str.contains(\"pdf\")]\n",
    "\n",
    "cols = [\"autoridades_apoiadas\",\"origem\",\"decolagem_h_local\",\"destino\",\"pouso_h_local\",\"motivo\",\"previsao_de_passageiros\",\"file_name\"]\n",
    "data = data[cols] # select specific cols\n",
    "\n",
    "# Convert NaN values to empty string\n",
    "nan_value = float(\"NaN\")\n",
    "\n",
    "data.replace(\"\", nan_value, inplace=True)\n",
    "data.dropna(subset = [\"decolagem_h_local\"], inplace=True)\n",
    "\n",
    "# pd.DataFrame(data).to_csv(\"clean.csv\") # save for checking\n",
    "data[\"origem\"] = data['origem'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "data[\"origem\"] = data['origem'].str.strip()\n",
    "data[\"origem\"] = data[\"origem\"].apply(unidecode)\n",
    "\n",
    "g = data.groupby('origem').nunique().reset_index()\n",
    "\n",
    "# pd.DataFrame(g).to_csv(\"summary.csv\") # save for checking\n",
    "\n",
    "airports = pd.read_csv(\"airports.csv\")\n",
    "\n",
    "cols_names = [\"AirportID\", \"Name\", \"City\", \"Country\", \"IATA\", \"ICAO\", \"Latitude\", \"Longitude\", \"Altitude\", \"Timezone\", \"DST\", \"TZ_DB\", \"Type\", \"Source\"]\n",
    "airports.columns = cols_names\n",
    "\n",
    "# to lower\n",
    "airports[\"City\"] = airports[\"City\"].str.lower()\n",
    "# keep only cols of interest:\n",
    "airports = airports[[\"City\",\"Country\",\"Latitude\",\"Longitude\"]]\n",
    "g = g.merge(airports, left_on='origem', right_on='City', how=\"left\")\n",
    "\n",
    "pd.DataFrame(pd.DataFrame(g.groupby([\"origem\", \"Country\"]).head(1)).to_csv(\"merge_good.csv\")) # save for checking\n",
    "\n",
    "# g[g['ids'].str.contains(\"ball\")]\n",
    "g1 = g.loc[g['Country'].isna()]\n",
    "print(g1)\n",
    "#pd.DataFrame(pd.DataFrame(g1).to_csv(\"merge_bad.csv\")) # save for checking\n",
    "\n",
    "\n",
    "# print(g)\n",
    "# explore and groom data:\n",
    "## unique columns\n",
    "## clean df\n",
    "## summary origem and destino\n",
    "### might help: df.sort_values(by='value').groupby('date').head(2)\n",
    "## fix column types - number, date and str \n",
    "\n",
    "# for df in dfs:\n",
    "#     clean_df = clean_columns(df)\n",
    "#     print(clean_df.columns)\n",
    "\n",
    "\n",
    "# summary table\n",
    "# https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\n",
    "# docs: https://openflights.org/data.html\n",
    "# https://github.com/kelvins/Municipios-Brasileiros/blob/main/csv/municipios.csv\n",
    "# https://www.trilhaseaventuras.com.br/siglas-dos-principais-aeroportos-do-brasil-iata/\n",
    "# https://pt.wikipedia.org/wiki/Lista_de_aeroportos_do_Brasil_por_c%C3%B3digo_aeroportu%C3%A1rio_ICAO\n",
    "\n",
    "# codigo uf:\n",
    "# https://www.oobj.com.br/bc/article/quais-os-c%C3%B3digos-de-cada-uf-no-brasil-465.html\n",
    "\n",
    "## como as viagens mudaram - total, nacional/ internacional por mandatos\n",
    "## qual ministerio viajou mais? por mandato?\n",
    "## overlap routes\n",
    "### https://towardsdatascience.com/mapping-the-worlds-flight-paths-with-python-232b9f7271e5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24815c7cfd0f5d2c9970f30cf94da237d5e1f4c89b51e06390960dee5d8cfe9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
